<!DOCTYPE html>



  



<html class="theme-next pisces use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico?v=5.1.4">






  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="01-简介1.1-mr是什么 是什么 MapReduce是一个编程模型，用以进行大数据量的计算 Hadoop MapReduce是一个软件框架，基于该框架能够容易地编写应用程序，这些应用程序能够运行在由上千个商用机器组成的大集群上，并以一种可靠的，具有容错能力的方式并行地处理上TB级别的海量数据集   特点 软件框架 并行处理 可靠且容错 大规模集群 海量数据集">
<meta property="og:type" content="article">
<meta property="og:title" content="大数据学习04_mapreduce">
<meta property="og:url" content="http://21guns.top/2018/01/28/大数据学习04-mapreduce/index.html">
<meta property="og:site_name" content="Ry1ynn&#39;s blogs">
<meta property="og:description" content="01-简介1.1-mr是什么 是什么 MapReduce是一个编程模型，用以进行大数据量的计算 Hadoop MapReduce是一个软件框架，基于该框架能够容易地编写应用程序，这些应用程序能够运行在由上千个商用机器组成的大集群上，并以一种可靠的，具有容错能力的方式并行地处理上TB级别的海量数据集   特点 软件框架 并行处理 可靠且容错 大规模集群 海量数据集">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://ot12pfxkm.bkt.clouddn.com/18-1-28/3278474.jpg">
<meta property="og:updated_time" content="2019-03-22T13:17:52.800Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="大数据学习04_mapreduce">
<meta name="twitter:description" content="01-简介1.1-mr是什么 是什么 MapReduce是一个编程模型，用以进行大数据量的计算 Hadoop MapReduce是一个软件框架，基于该框架能够容易地编写应用程序，这些应用程序能够运行在由上千个商用机器组成的大集群上，并以一种可靠的，具有容错能力的方式并行地处理上TB级别的海量数据集   特点 软件框架 并行处理 可靠且容错 大规模集群 海量数据集">
<meta name="twitter:image" content="http://ot12pfxkm.bkt.clouddn.com/18-1-28/3278474.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://21guns.top/2018/01/28/大数据学习04-mapreduce/">





  <title>大数据学习04_mapreduce | Ry1ynn's blogs</title>
  










</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Ry1ynn's blogs</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://21guns.top/2018/01/28/大数据学习04-mapreduce/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ry1ynn">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ry1ynn's blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">大数据学习04_mapreduce</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-28T09:24:16+08:00">
                2018-01-28
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="01-简介"><a href="#01-简介" class="headerlink" title="01-简介"></a>01-简介</h1><h2 id="1-1-mr是什么"><a href="#1-1-mr是什么" class="headerlink" title="1.1-mr是什么"></a>1.1-mr是什么</h2><ul>
<li>是什么<ul>
<li>MapReduce是一个编程模型，用以进行大数据量的计算</li>
<li>Hadoop MapReduce是一个软件框架，基于该框架能够容易地编写应用程序，这些应用程序能够运行在由上千个商用机器组成的大集群上，并以一种可靠的，具有容错能力的方式并行地处理上TB级别的海量数据集</li>
</ul>
</li>
<li>特点<ul>
<li>软件框架</li>
<li>并行处理</li>
<li>可靠且容错</li>
<li>大规模集群</li>
<li>海量数据集</li>
</ul>
</li>
</ul>
<a id="more"></a>
<h2 id="1-2-mr做什么"><a href="#1-2-mr做什么" class="headerlink" title="1.2-mr做什么"></a>1.2-mr做什么</h2><ul>
<li>MapReduce的思想就是“分而治之”</li>
<li>Mapper负责“分”<ul>
<li>把复杂的任务分解为若干个“简单的任务”来处理。</li>
<li>简单的任务”包含三层含义：<ul>
<li>数据或计算的规模相对原任务要大大缩小</li>
<li>就近计算原则，任务会分配到存放着所需数据的节点上进行计算</li>
<li>这些小任务可以并行计算彼此间几乎没有依赖关系</li>
</ul>
</li>
</ul>
</li>
<li>Reducer负责对map阶段的结果进行汇总<ul>
<li>需要多少个reducer，具体情况具体分析</li>
<li>在mapred-site.xml配置文件里设置参数mapred.reduce.tasks的值，缺省值为1</li>
</ul>
</li>
</ul>
<ul>
<li><ol>
<li><ul>
<li>​</li>
</ul>
</li>
</ol>
</li>
</ul>
<h1 id="02-mr框架执行过程"><a href="#02-mr框架执行过程" class="headerlink" title="02-mr框架执行过程"></a>02-mr框架执行过程</h1><h2 id="2-1-简介"><a href="#2-1-简介" class="headerlink" title="2.1-简介"></a>2.1-简介</h2><ul>
<li>在Hadoop中，一个MapReduce作业会把输入的数据集切分为若干独立的数据块，由Map任务以完全并行的方式处理</li>
<li>框架会对Map的输出先进行排序，然后把结果输入给Reduce任务。</li>
<li>作业的输入和输出都会被存储在文件系统中，整个框架负责任务的调度和监控，以及重新执行已经关闭的任务</li>
<li>MapReduce框架和分布式文件系统是运行在一组相同的节点，计算节点和存储节点都是在一起的</li>
</ul>
<h2 id="2-2-mr框架的组成"><a href="#2-2-mr框架的组成" class="headerlink" title="2.2-mr框架的组成"></a>2.2-mr框架的组成</h2><ul>
<li>客户端client<ul>
<li>编写mapreduce程序</li>
<li>配置作业，提交作业</li>
</ul>
</li>
<li>JobTracker<ul>
<li>初始化作业并分配作业</li>
<li>与TaskTcacker双向通信</li>
<li>协调整个作业的执行</li>
</ul>
</li>
<li>TaskTracker<ul>
<li>接收到分配的作业后，执行Map或Reduce任务</li>
<li>保持与JobTracker的通信（涉及：心跳机制监控）</li>
<li>执行任务时候TaskTracker可以有n个，JobTracker则只会有一个（JobTracker只能有一个就和hdfs里namenode一样，存在单点故障）</li>
</ul>
</li>
<li>HDFS<ul>
<li>在其它实体间共享作业文件</li>
<li>保存作业的数据、配置信息等等，最后的结果也是保存在hdfs上面</li>
</ul>
</li>
</ul>
<h2 id="2-3-简单工作流程"><a href="#2-3-简单工作流程" class="headerlink" title="2.3-简单工作流程"></a>2.3-简单工作流程</h2><ol>
<li>作业的提交</li>
<li>作业的初始化</li>
<li>作业的分配</li>
<li>作业的执行</li>
<li>进程与状态的更新</li>
<li>作业的完成</li>
</ol>
<h2 id="2-4-简要运行步骤"><a href="#2-4-简要运行步骤" class="headerlink" title="2.4-简要运行步骤"></a>2.4-简要运行步骤</h2><ol>
<li><p><strong>客户端</strong>编写mapreduce程序（即理解为job），提交job到JobTracker</p>
</li>
<li><p><strong>JobTracker</strong>构建此job（分配job ID值）</p>
</li>
<li><p><strong>JobTracker</strong> 做相关的检查操作</p>
<ul>
<li>输出目录是否存在（若存在，JobTraker抛出错误给客户端；反之继续</li>
<li>输入目录是否存在（不存在，抛出错误；反之继续</li>
</ul>
</li>
<li><p><strong>JobTracker</strong>根据输入计算输入分片，即input split（分片计算不出来也抛错</p>
</li>
<li><p><strong>JobTracker</strong>为job配置其需要的资源</p>
</li>
<li><p><strong>JobTracker</strong>初始化该job</p>
<ul>
<li>将job放入内部队列，以便能够被作业调度器调度到</li>
<li>作业调度器初始化此job，即创建job对象，以便JobTracker跟踪job的状态和进程</li>
</ul>
</li>
<li><p><strong>JobTracker</strong>，作业调度器会获取输入分片（input split）的信息，为每个分片创建map任务</p>
</li>
<li><p>JobTracker分配任务至TaskTracker</p>
<p>此时TT会运行简单的循环机制定期发送心跳给jobtracker</p>
<ul>
<li>心跳间隔是5秒，可自行配置这个时间</li>
<li>心跳就是jobtracker和tasktracker沟通的桥梁<ul>
<li>通过心跳，jobtracker可以监控tasktracker是否存活</li>
<li>也可以获取tasktracker处理的状态和问题</li>
<li>同时tasktracker也可以通过心跳里的返回值获取jobtracker给它的操作指令。</li>
</ul>
</li>
</ul>
</li>
<li><p>任务分配后便就是执行任务了</p>
<ul>
<li>任务执行时候jobtracker可以通过心跳机制监控tasktracker的状态和进度</li>
<li>同时也能计算出整个job的状态和进度</li>
<li>而tasktracker也可以本地监控自己的状态和进度</li>
</ul>
</li>
<li><p>任务执行完成</p>
<ul>
<li>当jobtracker获得了最后一个完成指定任务的tasktracker操作成功的通知时候，jobtracker会把整个job状态置为成功</li>
<li>当客户端查询job运行状态时候（注意：这个是异步操作），客户端会查到job完成的通知的。</li>
<li>如果job中途失败，mapreduce也会有相应机制处理，一般而言如果不是程序员程序本身有bug，mapreduce错误处理机制都能保证提交的job能正常完成。</li>
</ul>
</li>
</ol>
<h2 id="2-5-mr的输入输出"><a href="#2-5-mr的输入输出" class="headerlink" title="2.5-mr的输入输出"></a>2.5-mr的输入输出</h2><ul>
<li><p>有三组<code>&lt;key,value&gt;</code>键值对类型的存在</p>
<p><img src="http://ot12pfxkm.bkt.clouddn.com/18-1-28/3278474.jpg" alt></p>
</li>
</ul>
<h2 id="2-6-mr作业的处理流程"><a href="#2-6-mr作业的处理流程" class="headerlink" title="2.6-mr作业的处理流程"></a>2.6-mr作业的处理流程</h2><ul>
<li><p>按照时间顺序包括：</p>
<ul>
<li>输入分片（input split）</li>
<li>map阶段</li>
<li>combiner阶段</li>
<li>shuffle阶段</li>
<li>reduce阶段</li>
</ul>
</li>
<li><p>输入分片（input split）</p>
<ul>
<li>在进行map计算之前，mapreduce会根据输入文件计算输入分片（input split）</li>
<li>每个输入分片（input split）针对一个map任务</li>
<li>输入分片（input split）存储的并非数据本身，而是一个分片长度和一个记录数据位置的数组</li>
<li>输入分片（input split）往往和hdfs的block（块）关系很密切</li>
<li>假如我们设定hdfs的块的大小是64mb，如果我们输入有三个文件，大小分别是3mb、65mb和127mb，那么mapreduce会把3mb文件分为一个输入分片（input split），65mb则是两个输入分片（input split）而127mb也是两个输入分片（input split）</li>
<li>即我们如果在map计算前做输入分片调整，例如合并小文件，那么就会有5个map任务将执行，而且每个map执行的数据大小不均，这个也是mapreduce优化计算的一个关键点。</li>
</ul>
</li>
<li><p>map阶段</p>
<ul>
<li>map函数在客户端编写</li>
<li>好的map函数了，因此map函数效率相对好控制，而且一般map操作都是本地化操作也就是在数据存储节点上进行</li>
</ul>
</li>
<li><p>combiner阶段</p>
<ul>
<li><p>combiner阶段是程序员可以选择的，combiner其实也是一种reduce操作，因此我们看见WordCount类里是用reduce进行加载的</p>
</li>
<li><p>Combiner是一个本地化的reduce操作，它是map运算的后续操作，主要是在map计算出中间文件前做一个简单的合并重复key值的操作</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Combiner是一个本地化的reduce操作，它是map运算的后续操作，主要是在map计算出中间文件前做一个简单的合并重复key值的操作，例如我们对文件里的单词频率做统计，map计算时候如果碰到一个hadoop的单词就会记录为1，但是这篇文章里hadoop可能会出现n多次，那么map输出文件冗余就会很多，因此在reduce计算前对相同的key做一个合并操作，那么文件会变小，这样就提高了宽带的传输效率，毕竟hadoop计算力宽带资源往往是计算的瓶颈也是最为宝贵的资源，但是combiner操作是有风险的，使用它的原则是combiner的输入不会影响到reduce计算的最终输入，</span><br></pre></td></tr></table></figure>
</li>
<li><p>但是combiner操作是有风险的，使用它的原则是combiner的输入不会影响到reduce计算的最终输入</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">例如：如果计算只是求总数，最大值，最小值可以使用combiner，但是做平均值计算使用combiner的话，最终的reduce计算结果就会出错</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
<li><p>shuffle阶段</p>
<ul>
<li>将map的输出作为reduce的输入的过程就是shuffle了</li>
<li>reduce阶段<ul>
<li>和map函数一样也是程序员编写的</li>
<li>最终结果是存储在hdfs上的</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="2-7-其它：jobtracker的单点故障"><a href="#2-7-其它：jobtracker的单点故障" class="headerlink" title="2.7-其它：jobtracker的单点故障"></a>2.7-其它：jobtracker的单点故障</h2><ul>
<li>jobtracker和hdfs的namenode一样也存在单点故障</li>
<li>单点故障一直是hadoop被人诟病的大问题</li>
<li>为什么hadoop的做的文件系统和mapreduce计算框架都是高容错的，但是最重要的管理节点的故障机制却如此不好<ul>
<li>主要是namenode和jobtracker在实际运行中都是在内存操作，而做到内存的容错就比较复杂了，只有当内存数据被持久化后容错才好做</li>
<li>namenode和jobtracker都可以备份自己持久化的文件，但是这个持久化都会有延迟，因此真的出故障，任然不能整体恢复</li>
</ul>
</li>
<li>另外hadoop框架里包含zookeeper框架，zookeeper可以结合jobtracker，用几台机器同时部署jobtracker，保证一台出故障，有一台马上能补充上，不过这种方式也没法恢复正在跑的mapreduce任务。</li>
</ul>
<h1 id="03-wordcount源码解读"><a href="#03-wordcount源码解读" class="headerlink" title="03-wordcount源码解读"></a>03-wordcount源码解读</h1><h2 id="3-1-map方法"><a href="#3-1-map方法" class="headerlink" title="3.1-map方法"></a>3.1-map方法</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;…&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>前两个参数Object key, Text value就是输入的key和value，</li>
<li>第三个参数Context context这是可以记录输入的key和value<ul>
<li>例如：context.write(word, one);</li>
<li>此外context还会记录map运算的状态。</li>
</ul>
</li>
</ul>
<h2 id="3-2-reduce方法"><a href="#3-2-reduce方法" class="headerlink" title="3.2-reduce方法"></a>3.2-reduce方法</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;…&#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>reduce函数的输入也是一个key/value的形式</li>
<li>不过它的value是一个迭代器的形式Iterable<intwritable> values</intwritable></li>
<li>也就是说reduce的输入是一个key对应一组的值的value</li>
<li>reduce也有context和map的context作用一致</li>
</ul>
<h2 id="3-3-main函数"><a href="#3-3-main函数" class="headerlink" title="3.3-main函数"></a>3.3-main函数</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">    Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line">    String[] otherArgs = <span class="keyword">new</span> GenericOptionsParser(conf, args).getRemainingArgs();</span><br><span class="line">    <span class="keyword">if</span> (otherArgs.length != <span class="number">2</span>) &#123;</span><br><span class="line">      System.err.println(<span class="string">"Usage: wordcount &lt;in&gt; &lt;out&gt;"</span>);</span><br><span class="line">      System.exit(<span class="number">2</span>);</span><br><span class="line">    &#125;</span><br><span class="line">    Job job = <span class="keyword">new</span> Job(conf, <span class="string">"word count"</span>);</span><br><span class="line">    job.setJarByClass(WordCount.class);</span><br><span class="line">    job.setMapperClass(TokenizerMapper.class);</span><br><span class="line">    job.setCombinerClass(IntSumReducer.class);</span><br><span class="line">    job.setReducerClass(IntSumReducer.class);</span><br><span class="line">    job.setOutputKeyClass(Text.class);</span><br><span class="line">    job.setOutputValueClass(IntWritable.class);</span><br><span class="line">    FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(otherArgs[<span class="number">0</span>]));</span><br><span class="line">    FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(otherArgs[<span class="number">1</span>]));</span><br><span class="line">    System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line">  &#125;</span><br></pre></td></tr></table></figure>
<ul>
<li><p>代码-01：</p>
<p><code>Configuration conf = new Configuration();</code></p>
<ul>
<li>运行mapreduce程序前都要初始化Configuration</li>
<li>该类主要是读取mapreduce系统配置信息，这些信息包括hdfs还有mapreduce，也就是安装hadoop时候的配置文件</li>
<li>例如：core-site.xml、hdfs-site.xml和mapred-site.xml等等文件里的信息</li>
</ul>
<blockquote>
<p>程序员开发mapreduce时候只是在填空，在map函数和reduce函数里编写实际进行的业务逻辑，其它的工作都是交给mapreduce框架自己操作的，但是至少我们要告诉它怎么操作啊，比如hdfs在哪里啊，mapreduce的jobstracker在哪里啊，而这些信息就在conf包下的配置文件里。</p>
</blockquote>
</li>
<li><p>代码02</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">String[] otherArgs = <span class="keyword">new</span> GenericOptionsParser(conf, args).getRemainingArgs();</span><br><span class="line">    <span class="keyword">if</span> (otherArgs.length != <span class="number">2</span>) &#123;</span><br><span class="line">      System.err.println(<span class="string">"Usage: wordcount &lt;in&gt; &lt;out&gt;"</span>);</span><br><span class="line">      System.exit(<span class="number">2</span>);</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>
<ul>
<li>If的语句好理解，就是运行WordCount程序时候一定是两个参数，如果不是就会报错退出。</li>
<li>至于第一句里的GenericOptionsParser类，它是用来解释常用hadoop命令，并根据需要为Configuration对象设置相应的值（其实平时开发里我们不太常用它，而是让类实现Tool接口，然后再main函数里使用ToolRunner运行程序，而ToolRunner内部会调用GenericOptionsParser）</li>
</ul>
</li>
<li><p>代码03</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Job job = <span class="keyword">new</span> Job(conf, <span class="string">"word count"</span>);</span><br><span class="line">job.setJarByClass(WordCount.class);</span><br><span class="line">job.setMapperClass(TokenizerMapper.class);</span><br><span class="line">job.setCombinerClass(IntSumReducer.class);</span><br><span class="line">job.setReducerClass(IntSumReducer.class);</span><br></pre></td></tr></table></figure>
<ul>
<li>第一行就是在构建一个job<ul>
<li>在mapreduce框架里一个mapreduce任务也叫mapreduce作业也叫做一个mapreduce的job，而具体的map和reduce运算就是task了</li>
<li>这里我们构建一个job，构建时候有两个参数，一个是conf，一个是这个job的名称</li>
</ul>
</li>
<li>第二行就是装载程序员编写好的计算程序<ul>
<li>例如我们的程序类名就是WordCount了。</li>
<li>虽然我们编写mapreduce程序只需要实现map函数和reduce函数，但是实际开发我们要实现三个类</li>
<li>第三个类是为了配置mapreduce如何运行map和reduce函数，准确的说就是构建一个mapreduce能执行的job了，例如WordCount类。</li>
</ul>
</li>
<li>第三行和第五行就是装载map函数和reduce函数实现类了，</li>
<li>第四行，这个是装载Combiner类，其实本例去掉第四行也没有关系，但是使用了第四行理论上运行效率会更好。</li>
</ul>
</li>
<li><p>代码04</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">job.setOutputKeyClass(Text.class);</span><br><span class="line">job.setOutputValueClass(IntWritable.class);</span><br></pre></td></tr></table></figure>
<ul>
<li>定义输出的key/value的类型，也就是最终存储在hdfs上结果文件的key/value的类型</li>
</ul>
</li>
<li><p>代码05</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(otherArgs[<span class="number">0</span>]));</span><br><span class="line">FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(otherArgs[<span class="number">1</span>]));</span><br><span class="line">System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br></pre></td></tr></table></figure>
<ul>
<li>第一行就是构建输入的数据文件</li>
<li>第二行是构建输出的数据文件</li>
<li>最后一行如果job运行成功了，我们的程序就会正常退出。</li>
<li>FileInputFormat和FileOutputFormat可以设置输入输出文件路径，<ul>
<li>mapreduce计算时候，输入文件必须存在，要不直Mr任务直接退出。</li>
<li>输出一般是一个文件夹，而且该文件夹不能存在</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="3-4-总体代码解读"><a href="#3-4-总体代码解读" class="headerlink" title="3.4-总体代码解读"></a>3.4-总体代码解读</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/** </span></span><br><span class="line"><span class="comment"> * Licensed to the Apache Software Foundation (ASF) under one </span></span><br><span class="line"><span class="comment"> * or more contributor license agreements.  See the NOTICE file </span></span><br><span class="line"><span class="comment"> * distributed with this work for additional information </span></span><br><span class="line"><span class="comment"> * regarding copyright ownership.  The ASF licenses this file </span></span><br><span class="line"><span class="comment"> * to you under the Apache License, Version 2.0 (the </span></span><br><span class="line"><span class="comment"> * "License"); you may not use this file except in compliance </span></span><br><span class="line"><span class="comment"> * with the License.  You may obtain a copy of the License at </span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> *     http://www.apache.org/licenses/LICENSE-2.0 </span></span><br><span class="line"><span class="comment"> * </span></span><br><span class="line"><span class="comment"> * Unless required by applicable law or agreed to in writing, software </span></span><br><span class="line"><span class="comment"> * distributed under the License is distributed on an "AS IS" BASIS, </span></span><br><span class="line"><span class="comment"> * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. </span></span><br><span class="line"><span class="comment"> * See the License for the specific language governing permissions and </span></span><br><span class="line"><span class="comment"> * limitations under the License. </span></span><br><span class="line"><span class="comment"> */</span>  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line"><span class="keyword">package</span> org.apache.hadoop.examples;  </span><br><span class="line"><span class="keyword">import</span> java.io.IOException;  </span><br><span class="line"><span class="keyword">import</span> java.util.StringTokenizer;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.IntWritable;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.io.Text;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Job;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Mapper;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.Reducer;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.input.FileInputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;  </span><br><span class="line"><span class="keyword">import</span> org.apache.hadoop.util.GenericOptionsParser;  </span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCount</span> </span>&#123;  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">//四个参数，前两个为输入&lt;key,value&gt;对，后两个为输出&lt;key,value&gt;对;  </span></span><br><span class="line">    <span class="comment">//LongWritable、IntWritable、Text可视为Java 的long、int、String替代品;  </span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">TokenizerMapper</span> <span class="keyword">extends</span> <span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt;</span>&#123;  </span><br><span class="line">            <span class="comment">//一个标记单词个数的常量，值为1，这个常量也可以不定义，在后面程序直接用整数1代替，private final static定义的是常量;  </span></span><br><span class="line">        <span class="keyword">private</span> <span class="keyword">final</span> <span class="keyword">static</span> IntWritable one = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);  </span><br><span class="line">        <span class="comment">//充当中间变量，存储词;  </span></span><br><span class="line">        <span class="keyword">private</span> Text word = <span class="keyword">new</span> Text();  </span><br><span class="line">        <span class="comment">//map方法，key为偏移量，对value进行拆分，&lt;span style="font-family: Arial, Helvetica, sans-serif;"&gt;context为上下文机制;&lt;/span&gt;  </span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;  </span><br><span class="line">            <span class="comment">//对转换的字符串进行分隔;   </span></span><br><span class="line">            StringTokenizer itr = <span class="keyword">new</span> StringTokenizer(value.toString());  </span><br><span class="line">                <span class="comment">//利用循环函数进行依次处理;  </span></span><br><span class="line">            <span class="keyword">while</span> (itr.hasMoreTokens()) &#123;  </span><br><span class="line">                <span class="comment">//返回从当前位置到下一个分隔符的字符串;       </span></span><br><span class="line">                word.set(itr.nextToken());  </span><br><span class="line">                <span class="comment">//如 context.write("hello",1);  </span></span><br><span class="line">                context.write(word, one);      </span><br><span class="line">            &#125;  </span><br><span class="line">          &#125;  </span><br><span class="line">         &#125;  </span><br><span class="line">    </span><br><span class="line">    <span class="comment">//四个参数，前两个为输入&lt;key,value&gt;对，后两个为输出&lt;key,value&gt;对;  </span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">IntSumReducer</span> <span class="keyword">extends</span> <span class="title">Reducer</span>&lt;<span class="title">Text</span>,<span class="title">IntWritable</span>,<span class="title">Text</span>,<span class="title">IntWritable</span>&gt; </span>&#123;  </span><br><span class="line">        <span class="comment">//定义一个变量;  </span></span><br><span class="line">            <span class="keyword">private</span> IntWritable result = <span class="keyword">new</span> IntWritable();  </span><br><span class="line">        <span class="comment">//reduce方法，key为如 "hello"，Iterable遍历所有key的个数;  </span></span><br><span class="line">                <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values,Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;  </span><br><span class="line">                <span class="comment">//  用于记录key个数的变量;  </span></span><br><span class="line">                    <span class="keyword">int</span> sum = <span class="number">0</span>;  </span><br><span class="line">            <span class="comment">//求key的个数;   </span></span><br><span class="line">                    <span class="keyword">for</span> (IntWritable val : values) &#123;  </span><br><span class="line">                                sum += val.get();  </span><br><span class="line">                    &#125;  </span><br><span class="line">            <span class="comment">//把sum个数存到result中去;  </span></span><br><span class="line">                    result.set(sum);  </span><br><span class="line">            <span class="comment">//如 context.write("hello",7);        </span></span><br><span class="line">                    context.write(key, result);  </span><br><span class="line">                &#125;  </span><br><span class="line">        &#125;  </span><br><span class="line">  </span><br><span class="line">  </span><br><span class="line">    <span class="comment">//主方法;  </span></span><br><span class="line">        <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;  </span><br><span class="line">        <span class="comment">//指定作业执行规范;  </span></span><br><span class="line">            Configuration conf = <span class="keyword">new</span> Configuration();  </span><br><span class="line">            <span class="comment">//这里需要配置参数即输入和输出的HDFS的文件路径   </span></span><br><span class="line">        String[] otherArgs = <span class="keyword">new</span> GenericOptionsParser(conf, args).getRemainingArgs();  </span><br><span class="line">        <span class="keyword">if</span> (otherArgs.length &lt; <span class="number">2</span>) &#123;  </span><br><span class="line">                    System.err.println(<span class="string">"Usage: wordcount &lt;in&gt; [&lt;in&gt;...] &lt;out&gt;"</span>);  </span><br><span class="line">                System.exit(<span class="number">2</span>);  </span><br><span class="line">        &#125;  </span><br><span class="line">        <span class="comment">//设置Job名称、运行对象;  </span></span><br><span class="line">        Job job = <span class="keyword">new</span> Job(conf, <span class="string">"word count"</span>);  </span><br><span class="line">            job.setJarByClass(WordCount.class);  </span><br><span class="line">        <span class="comment">//为job设置map类;  </span></span><br><span class="line">        job.setMapperClass(TokenizerMapper.class);  </span><br><span class="line">        <span class="comment">//为job设置Combiner类;  </span></span><br><span class="line">        job.setCombinerClass(IntSumReducer.class);  </span><br><span class="line">        <span class="comment">//为job设置 reduce类;  </span></span><br><span class="line">        job.setReducerClass(IntSumReducer.class);  </span><br><span class="line">            <span class="comment">//设置输出key类型;  </span></span><br><span class="line">        job.setOutputKeyClass(Text.class);  </span><br><span class="line">        <span class="comment">//设置输出value类型;  </span></span><br><span class="line">        job.setOutputValueClass(IntWritable.class);  </span><br><span class="line">        <span class="comment">//设置输入路径;  </span></span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; otherArgs.length - <span class="number">1</span>; ++i) &#123;  </span><br><span class="line">                FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(otherArgs[i]));  </span><br><span class="line">        &#125;  </span><br><span class="line">        <span class="comment">//设置输出路径;  </span></span><br><span class="line">        FileOutputFormat.setOutputPath(job,<span class="keyword">new</span> Path(otherArgs[otherArgs.length - <span class="number">1</span>]));  </span><br><span class="line">        System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);  </span><br><span class="line">     &#125;  </span><br><span class="line">  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/01/27/Kali实战-Skipfish/" rel="next" title="Kali实战-Skipfish">
                <i class="fa fa-chevron-left"></i> Kali实战-Skipfish
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/01/28/大数据学习03-HDFS/" rel="prev" title="大数据学习03_HDFS">
                大数据学习03_HDFS <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="Ry1ynn">
            
              <p class="site-author-name" itemprop="name">Ry1ynn</p>
              <p class="site-description motion-element" itemprop="description">我们的征途是星辰大海</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">130</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">20</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">58</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/Ry1ynn" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:ry1ynn_pri@163.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://weibo.com/u/" target="_blank" title="Weibo">
                      
                        <i class="fa fa-fw fa-weibo"></i>Weibo</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="/images/weixin.JPG" target="_blank" title="Wechat">
                      
                        <i class="fa fa-fw fa-weixin"></i>Wechat</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.t00ls.net/" title="T00ls" target="_blank">T00ls</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.freebuf.com/" title="FreeBuf" target="_blank">FreeBuf</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.sec-wiki.com/" title="SecWiki" target="_blank">SecWiki</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.seebug.org/" title="Seebug" target="_blank">Seebug</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.91ri.org/" title="91Ri" target="_blank">91Ri</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.pediy.com/" title="看雪" target="_blank">看雪</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.52pojie.cn/" title="吾爱破解" target="_blank">吾爱破解</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.anquanke.com/" title="安全客" target="_blank">安全客</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.ichunqiu.com/" title="i春秋" target="_blank">i春秋</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#01-简介"><span class="nav-text">01-简介</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#1-1-mr是什么"><span class="nav-text">1.1-mr是什么</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#1-2-mr做什么"><span class="nav-text">1.2-mr做什么</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#02-mr框架执行过程"><span class="nav-text">02-mr框架执行过程</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-简介"><span class="nav-text">2.1-简介</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-mr框架的组成"><span class="nav-text">2.2-mr框架的组成</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-简单工作流程"><span class="nav-text">2.3-简单工作流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-4-简要运行步骤"><span class="nav-text">2.4-简要运行步骤</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-5-mr的输入输出"><span class="nav-text">2.5-mr的输入输出</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-6-mr作业的处理流程"><span class="nav-text">2.6-mr作业的处理流程</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-7-其它：jobtracker的单点故障"><span class="nav-text">2.7-其它：jobtracker的单点故障</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#03-wordcount源码解读"><span class="nav-text">03-wordcount源码解读</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#3-1-map方法"><span class="nav-text">3.1-map方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-2-reduce方法"><span class="nav-text">3.2-reduce方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-3-main函数"><span class="nav-text">3.3-main函数</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#3-4-总体代码解读"><span class="nav-text">3.4-总体代码解读</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2016 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ry1ynn</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  










  



  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script id="ribbon" type="text/javascript" size="300" alpha="0.5" zindex="0" src="/lib/canvas-ribbon/canvas-ribbon.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
