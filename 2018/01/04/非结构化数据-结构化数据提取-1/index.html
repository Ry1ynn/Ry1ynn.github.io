<!DOCTYPE html>



  



<html class="theme-next pisces use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon.ico?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon.ico?v=5.1.4">






  <meta name="keywords" content="python,爬虫,数据提取,">










<meta name="description" content="非结构化数据&amp;amp;结构化数据提取00-简介 一般来讲对我们而言，需要抓取的是某个网站或者某个应用的内容，提取有用的价值。内容一般分为两部分，非结构化的数据 和 结构化的数据。 非结构化数据：先有数据，再有结构， 结构化数据：先有结构、再有数据 不同类型的数据，我们需要采用不同的方式来处理。   非结构化的数据处理">
<meta name="keywords" content="python,爬虫,数据提取">
<meta property="og:type" content="article">
<meta property="og:title" content="非结构化数据&amp;结构化数据提取-1">
<meta property="og:url" content="http://21guns.top/2018/01/04/非结构化数据-结构化数据提取-1/index.html">
<meta property="og:site_name" content="Ry1ynn&#39;s blogs">
<meta property="og:description" content="非结构化数据&amp;amp;结构化数据提取00-简介 一般来讲对我们而言，需要抓取的是某个网站或者某个应用的内容，提取有用的价值。内容一般分为两部分，非结构化的数据 和 结构化的数据。 非结构化数据：先有数据，再有结构， 结构化数据：先有结构、再有数据 不同类型的数据，我们需要采用不同的方式来处理。   非结构化的数据处理">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://ot12pfxkm.bkt.clouddn.com/18-1-4/65425390.jpg">
<meta property="og:image" content="http://ot12pfxkm.bkt.clouddn.com/18-1-4/60983452.jpg">
<meta property="og:image" content="http://ot12pfxkm.bkt.clouddn.com/18-1-4/95218382.jpg">
<meta property="og:image" content="http://ot12pfxkm.bkt.clouddn.com/18-1-4/63978114.jpg">
<meta property="og:image" content="http://ot12pfxkm.bkt.clouddn.com/18-1-4/92466482.jpg">
<meta property="og:updated_time" content="2019-02-18T09:14:40.807Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="非结构化数据&amp;结构化数据提取-1">
<meta name="twitter:description" content="非结构化数据&amp;amp;结构化数据提取00-简介 一般来讲对我们而言，需要抓取的是某个网站或者某个应用的内容，提取有用的价值。内容一般分为两部分，非结构化的数据 和 结构化的数据。 非结构化数据：先有数据，再有结构， 结构化数据：先有结构、再有数据 不同类型的数据，我们需要采用不同的方式来处理。   非结构化的数据处理">
<meta name="twitter:image" content="http://ot12pfxkm.bkt.clouddn.com/18-1-4/65425390.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://21guns.top/2018/01/04/非结构化数据-结构化数据提取-1/">





  <title>非结构化数据&结构化数据提取-1 | Ry1ynn's blogs</title>
  










</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Ry1ynn's blogs</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://21guns.top/2018/01/04/非结构化数据-结构化数据提取-1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Ry1ynn">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ry1ynn's blogs">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">非结构化数据&结构化数据提取-1</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-04T17:06:11+08:00">
                2018-01-04
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/python/爬虫/" itemprop="url" rel="index">
                    <span itemprop="name">爬虫</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="非结构化数据-amp-结构化数据提取"><a href="#非结构化数据-amp-结构化数据提取" class="headerlink" title="非结构化数据&amp;结构化数据提取"></a>非结构化数据&amp;结构化数据提取</h1><h2 id="00-简介"><a href="#00-简介" class="headerlink" title="00-简介"></a>00-简介</h2><ul>
<li>一般来讲对我们而言，需要抓取的是某个网站或者某个应用的内容，提取有用的价值。内容一般分为两部分，非结构化的数据 和 结构化的数据。<ul>
<li>非结构化数据：先有数据，再有结构，</li>
<li>结构化数据：先有结构、再有数据</li>
<li>不同类型的数据，我们需要采用不同的方式来处理。</li>
</ul>
</li>
<li>非结构化的数据处理<a id="more"></a><ul>
<li>文本、电话号码、邮箱地址<ul>
<li>正则表达式</li>
</ul>
</li>
<li>HTML 文件<ul>
<li>正则表达式</li>
<li>XPath</li>
<li>CSS选择器</li>
</ul>
</li>
</ul>
</li>
<li>结构化的数据处理<ul>
<li>JSON 文件<ul>
<li>JSON Path</li>
<li>转化成Python类型进行操作（json类）</li>
</ul>
</li>
<li>XML 文件<ul>
<li>转化成Python类型（xmltodict）<br>XPath<br>CSS选择器<br>正则表达式</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="01-正则表达式re模块"><a href="#01-正则表达式re模块" class="headerlink" title="01-正则表达式re模块"></a>01-正则表达式re模块</h2><h3 id="1-1-为何学正则表达式"><a href="#1-1-为何学正则表达式" class="headerlink" title="1.1-为何学正则表达式"></a>1.1-为何学正则表达式</h3><ul>
<li>实际上爬虫一共就四个主要步骤：<ol>
<li>明确目标 (要知道你准备在哪个范围或者网站去搜索)</li>
<li>爬 (将所有的网站的内容全部爬下来)</li>
<li>取 (去掉对我们没用处的数据)</li>
<li>处理数据（按照我们想要的方式存储和使用）</li>
</ol>
</li>
<li>我们在昨天的案例里实际上省略了第3步，也就是”取”的步骤。因为我们down下了的数据是全部的网页，这些数据很庞大并且很混乱，大部分的东西使我们不关心的，因此我们需要将之按我们的需要过滤和匹配出来。</li>
<li>那么对于文本的过滤或者规则的匹配，最强大的就是正则表达式，是Python爬虫世界里必不可少的神兵利器。</li>
</ul>
<h3 id="1-2-何为正则表达式"><a href="#1-2-何为正则表达式" class="headerlink" title="1.2-何为正则表达式"></a>1.2-何为正则表达式</h3><ul>
<li><p>正则表达式，又称规则表达式，通常被用来检索、替换那些符合某个模式(规则)的文本。</p>
</li>
<li><p>正则表达式是对字符串操作的一种逻辑公式，就是用事先定义好的一些特定字符、及这些特定字符的组合，组成一个“规则字符串”，这个“规则字符串”用来表达对字符串的一种过滤逻辑。</p>
</li>
<li><p>给定一个正则表达式和另一个字符串，我们可以达到如下的目的：</p>
<ul>
<li>给定的字符串是否符合正则表达式的过滤逻辑（“匹配”）；</li>
<li>通过正则表达式，从文本字符串中获取我们想要的特定部分（“过滤”）。</li>
</ul>
</li>
<li><p>图示：</p>
<p><img src="http://ot12pfxkm.bkt.clouddn.com/18-1-4/65425390.jpg" alt></p>
</li>
</ul>
<h3 id="1-3-正则表达式匹配规则"><a href="#1-3-正则表达式匹配规则" class="headerlink" title="1.3-正则表达式匹配规则"></a>1.3-正则表达式匹配规则</h3><ul>
<li><p>图示</p>
<p><img src="http://ot12pfxkm.bkt.clouddn.com/18-1-4/60983452.jpg" alt></p>
</li>
</ul>
<h3 id="1-4-python中的re模块"><a href="#1-4-python中的re模块" class="headerlink" title="1.4-python中的re模块"></a>1.4-python中的re模块</h3><ul>
<li><p>在 Python 中，我们可以使用内置的 re 模块来使用正则表达式。</p>
</li>
<li><p>有一点需要特别注意的是，正则表达式使用 对特殊字符进行转义，所以如果我们要使用原始字符串，只需加一个 r 前缀，示例：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">r'chuanzhiboke\t\.\tpython'</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>re 模块的一般使用步骤如下：</p>
<ul>
<li>使用 <code>compile()</code> 函数将正则表达式的字符串形式编译为一个 <code>Pattern</code> 对象</li>
<li>通过 <code>Pattern</code> 对象提供的一系列方法对文本进行匹配查找，获得匹配结果，一个 Match 对象。</li>
<li>最后使用 <code>Match</code> 对象提供的属性和方法获得信息，根据需要进行其他的操作</li>
</ul>
</li>
</ul>
<h4 id="compile函数"><a href="#compile函数" class="headerlink" title="compile函数"></a>compile函数</h4><ul>
<li><p>compile 函数用于编译正则表达式，生成一个 Pattern 对象，它的一般使用形式如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将正则表达式编译成 Pattern 对象</span></span><br><span class="line">pattern = re.compile(<span class="string">r'\d+'</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>在上面，我们已将一个正则表达式编译成 Pattern 对象，接下来，我们就可以利用 pattern 的一系列方法对文本进行匹配查找了。</p>
</li>
<li><p>Pattern 对象的一些常用方法主要有：</p>
<ul>
<li>match 方法：从起始位置开始查找，一次匹配</li>
<li>search 方法：从任何位置开始查找，一次匹配</li>
<li>findall 方法：全部匹配，返回列表</li>
<li>finditer 方法：全部匹配，返回迭代器</li>
<li>split 方法：分割字符串，返回列表</li>
<li>sub 方法：替换</li>
</ul>
</li>
</ul>
<h4 id="match-方法"><a href="#match-方法" class="headerlink" title="match 方法"></a>match 方法</h4><ul>
<li><p>match 方法用于查找字符串的头部（也可以指定起始位置），它是一次匹配，只要找到了一个匹配的结果就返回，而不是查找所有匹配的结果。它的一般使用形式如下</p>
<p><code>match(string[, pos[, endpos]])</code></p>
</li>
<li><p>其中，string 是待匹配的字符串，pos 和 endpos 是可选参数，指定字符串的起始和终点位置，默认值分别是 0 和 len (字符串长度)。因此，当你不指定 pos 和 endpos 时，match 方法默认匹配字符串的头部。</p>
</li>
<li><p>当匹配成功时，返回一个 Match 对象，如果没有匹配上，则返回 None。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pattern = re.compile(<span class="string">r'\d+'</span>)  <span class="comment"># 用于匹配至少一个数字</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = pattern.match(<span class="string">'one12twothree34four'</span>)  <span class="comment"># 查找头部，没有匹配</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">print</span> m</span><br><span class="line"><span class="keyword">None</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = pattern.match(<span class="string">'one12twothree34four'</span>, <span class="number">2</span>, <span class="number">10</span>) <span class="comment"># 从'e'的位置开始匹配，没有匹配</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">print</span> m</span><br><span class="line"><span class="keyword">None</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = pattern.match(<span class="string">'one12twothree34four'</span>, <span class="number">3</span>, <span class="number">10</span>) <span class="comment"># 从'1'的位置开始匹配，正好匹配</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">print</span> m                                         <span class="comment"># 返回一个 Match 对象</span></span><br><span class="line">&lt;_sre.SRE_Match object at <span class="number">0x10a42aac0</span>&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.group(<span class="number">0</span>)   <span class="comment"># 可省略 0</span></span><br><span class="line"><span class="string">'12'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.start(<span class="number">0</span>)   <span class="comment"># 可省略 0</span></span><br><span class="line"><span class="number">3</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.end(<span class="number">0</span>)     <span class="comment"># 可省略 0</span></span><br><span class="line"><span class="number">5</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.span(<span class="number">0</span>)    <span class="comment"># 可省略 0</span></span><br><span class="line">(<span class="number">3</span>, <span class="number">5</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>在上面，当匹配成功时返回一个 Match 对象，其中：</p>
<ul>
<li>group([group1, …]) 方法用于获得一个或多个分组匹配的字符串，当要获得整个匹配的子串时，可直接使用 group() 或 group(0)；</li>
<li>start([group]) 方法用于获取分组匹配的子串在整个字符串中的起始位置（子串第一个字符的索引），参数默认值为 0；</li>
<li>end([group]) 方法用于获取分组匹配的子串在整个字符串中的结束位置（子串最后一个字符的索引+1），参数默认值为 0；</li>
<li>span([group]) 方法返回 (start(group), end(group))。</li>
</ul>
</li>
<li><p>一个例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pattern = re.compile(<span class="string">r'([a-z]+) ([a-z]+)'</span>, re.I)  <span class="comment"># re.I 表示忽略大小写</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = pattern.match(<span class="string">'Hello World Wide Web'</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">print</span> m     <span class="comment"># 匹配成功，返回一个 Match 对象</span></span><br><span class="line">&lt;_sre.SRE_Match object at <span class="number">0x10bea83e8</span>&gt;</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.group(<span class="number">0</span>)  <span class="comment"># 返回匹配成功的整个子串</span></span><br><span class="line"><span class="string">'Hello World'</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.span(<span class="number">0</span>)   <span class="comment"># 返回匹配成功的整个子串的索引</span></span><br><span class="line">(<span class="number">0</span>, <span class="number">11</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.group(<span class="number">1</span>)  <span class="comment"># 返回第一个分组匹配成功的子串</span></span><br><span class="line"><span class="string">'Hello'</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.span(<span class="number">1</span>)   <span class="comment"># 返回第一个分组匹配成功的子串的索引</span></span><br><span class="line">(<span class="number">0</span>, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.group(<span class="number">2</span>)  <span class="comment"># 返回第二个分组匹配成功的子串</span></span><br><span class="line"><span class="string">'World'</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.span(<span class="number">2</span>)   <span class="comment"># 返回第二个分组匹配成功的子串</span></span><br><span class="line">(<span class="number">6</span>, <span class="number">11</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.groups()  <span class="comment"># 等价于 (m.group(1), m.group(2), ...)</span></span><br><span class="line">(<span class="string">'Hello'</span>, <span class="string">'World'</span>)</span><br><span class="line"></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.group(<span class="number">3</span>)   <span class="comment"># 不存在第三个分组</span></span><br><span class="line">Traceback (most recent call last):</span><br><span class="line">  File <span class="string">"&lt;stdin&gt;"</span>, line <span class="number">1</span>, <span class="keyword">in</span> &lt;module&gt;</span><br><span class="line">IndexError: no such group</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="search方法"><a href="#search方法" class="headerlink" title="search方法"></a>search方法</h4><ul>
<li><p>search 方法用于查找字符串的任何位置，它也是一次匹配，只要找到了一个匹配的结果就返回，而不是查找所有匹配的结果，它的一般使用形式如下：</p>
<p><code>search(string[, pos[, endpos]])</code></p>
</li>
<li><p>其中，string 是待匹配的字符串，pos 和 endpos 是可选参数，指定字符串的起始和终点位置，默认值分别是 0 和 len (字符串长度)。</p>
</li>
<li><p>当匹配成功时，返回一个 Match 对象，如果没有匹配上，则返回 None。</p>
<p>让我们看看例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">import</span> re</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>pattern = re.compile(<span class="string">'\d+'</span>)</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = pattern.search(<span class="string">'one12twothree34four'</span>)  <span class="comment"># 这里如果使用 match 方法则不匹配</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m</span><br><span class="line">&lt;_sre.SRE_Match object at <span class="number">0x10cc03ac0</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.group()</span><br><span class="line"><span class="string">'12'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m = pattern.search(<span class="string">'one12twothree34four'</span>, <span class="number">10</span>, <span class="number">30</span>)  <span class="comment"># 指定字符串区间</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m</span><br><span class="line">&lt;_sre.SRE_Match object at <span class="number">0x10cc03b28</span>&gt;</span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.group()</span><br><span class="line"><span class="string">'34'</span></span><br><span class="line"><span class="meta">&gt;&gt;&gt; </span>m.span()</span><br><span class="line">(<span class="number">13</span>, <span class="number">15</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>再来看一个例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="comment"># 将正则表达式编译成 Pattern 对象</span></span><br><span class="line">pattern = re.compile(<span class="string">r'\d+'</span>)</span><br><span class="line"><span class="comment"># 使用 search() 查找匹配的子串，不存在匹配的子串时将返回 None</span></span><br><span class="line"><span class="comment"># 这里使用 match() 无法成功匹配</span></span><br><span class="line">m = pattern.search(<span class="string">'hello 123456 789'</span>)</span><br><span class="line"><span class="keyword">if</span> m:</span><br><span class="line">    <span class="comment"># 使用 Match 获得分组信息</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'matching string:'</span>,m.group()</span><br><span class="line">    <span class="comment"># 起始位置和结束位置</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'position:'</span>,m.span()</span><br></pre></td></tr></table></figure>
</li>
<li><p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">matching string: <span class="number">123456</span></span><br><span class="line">position: (<span class="number">6</span>, <span class="number">12</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="findall方法"><a href="#findall方法" class="headerlink" title="findall方法"></a>findall方法</h4><ul>
<li><p>上面的 match 和 search 方法都是一次匹配，只要找到了一个匹配的结果就返回。然而，在大多数时候，我们需要搜索整个字符串，获得所有匹配的结果。</p>
</li>
<li><p>findall 方法的使用形式如下：</p>
<p><code>findall(string[, pos[, endpos]])</code></p>
</li>
<li><p>其中，string 是待匹配的字符串，pos 和 endpos 是可选参数，指定字符串的起始和终点位置，默认值分别是 0 和 len (字符串长度)。</p>
</li>
<li><p>findall 以列表形式返回全部能匹配的子串，如果没有匹配，则返回一个空列表。</p>
<p>看看例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">pattern = re.compile(<span class="string">r'\d+'</span>)   <span class="comment"># 查找数字</span></span><br><span class="line"></span><br><span class="line">result1 = pattern.findall(<span class="string">'hello 123456 789'</span>)</span><br><span class="line">result2 = pattern.findall(<span class="string">'one1two2three3four4'</span>, <span class="number">0</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> result1</span><br><span class="line"><span class="keyword">print</span> result2</span><br></pre></td></tr></table></figure>
</li>
<li><p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">'123456'</span>, <span class="string">'789'</span>]</span><br><span class="line">[<span class="string">'1'</span>, <span class="string">'2'</span>]</span><br></pre></td></tr></table></figure>
</li>
<li><p>再先看一个栗子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># re_test.py</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"><span class="comment">#re模块提供一个方法叫compile模块，提供我们输入一个匹配的规则</span></span><br><span class="line"><span class="comment">#然后返回一个pattern实例，我们根据这个规则去匹配字符串</span></span><br><span class="line">pattern = re.compile(<span class="string">r'\d+\.\d*'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#通过partten.findall()方法就能够全部匹配到我们得到的字符串</span></span><br><span class="line">result = pattern.findall(<span class="string">"123.141593, 'bigcat', 232312, 3.15"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#findall 以 列表形式 返回全部能匹配的子串给result</span></span><br><span class="line"><span class="keyword">for</span> item <span class="keyword">in</span> result:</span><br><span class="line">    <span class="keyword">print</span> item</span><br></pre></td></tr></table></figure>
</li>
<li><p>运行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">123.141593</span></span><br><span class="line"><span class="number">3.15</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="finditer-方法"><a href="#finditer-方法" class="headerlink" title="finditer 方法"></a>finditer 方法</h4><ul>
<li><p>finditer 方法的行为跟 findall 的行为类似，也是搜索整个字符串，获得所有匹配的结果。但它返回一个顺序访问每一个匹配结果（Match 对象）的迭代器。</p>
</li>
<li><p>看看例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line">pattern = re.compile(<span class="string">r'\d+'</span>)</span><br><span class="line"></span><br><span class="line">result_iter1 = pattern.finditer(<span class="string">'hello 123456 789'</span>)</span><br><span class="line">result_iter2 = pattern.finditer(<span class="string">'one1two2three3four4'</span>, <span class="number">0</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> type(result_iter1)</span><br><span class="line"><span class="keyword">print</span> type(result_iter2)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">'result1...'</span></span><br><span class="line"><span class="keyword">for</span> m1 <span class="keyword">in</span> result_iter1:   <span class="comment"># m1 是 Match 对象</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'matching string: &#123;&#125;, position: &#123;&#125;'</span>.format(m1.group(), m1.span())</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> <span class="string">'result2...'</span></span><br><span class="line"><span class="keyword">for</span> m2 <span class="keyword">in</span> result_iter2:</span><br><span class="line">    <span class="keyword">print</span> <span class="string">'matching string: &#123;&#125;, position: &#123;&#125;'</span>.format(m2.group(), m2.span())</span><br></pre></td></tr></table></figure>
</li>
<li><p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">&lt;type <span class="string">'callable-iterator'</span>&gt;</span><br><span class="line">&lt;type <span class="string">'callable-iterator'</span>&gt;</span><br><span class="line">result1...</span><br><span class="line">matching string: <span class="number">123456</span>, position: (<span class="number">6</span>, <span class="number">12</span>)</span><br><span class="line">matching string: <span class="number">789</span>, position: (<span class="number">13</span>, <span class="number">16</span>)</span><br><span class="line">result2...</span><br><span class="line">matching string: <span class="number">1</span>, position: (<span class="number">3</span>, <span class="number">4</span>)</span><br><span class="line">matching string: <span class="number">2</span>, position: (<span class="number">7</span>, <span class="number">8</span>)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="split方法"><a href="#split方法" class="headerlink" title="split方法"></a>split方法</h4><ul>
<li><p>split 方法按照能够匹配的子串将字符串分割后返回列表，它的使用形式如下：</p>
<p><code>split(string[, maxsplit])</code></p>
<ul>
<li>其中，maxsplit 用于指定最大分割次数，不指定将全部分割。</li>
</ul>
</li>
<li><p>看看例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">p = re.compile(<span class="string">r'[\s\,\;]+'</span>)</span><br><span class="line"><span class="keyword">print</span> p.split(<span class="string">'a,b;; c   d'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#执行结果：</span></span><br><span class="line"><span class="comment">#['a', 'b', 'c', 'd']</span></span><br></pre></td></tr></table></figure>
</li>
<li></li>
</ul>
<h4 id="sub方法"><a href="#sub方法" class="headerlink" title="sub方法"></a>sub方法</h4><ul>
<li><p>sub 方法用于替换。它的使用形式如下：</p>
<p><code>sub(repl, string[, count])</code></p>
</li>
<li><p>其中，repl 可以是字符串也可以是一个函数：</p>
<ul>
<li>如果 repl 是字符串，则会使用 repl 去替换字符串每一个匹配的子串，并返回替换后的字符串，另外，repl 还可以使用 id 的形式来引用分组，但不能使用编号 0；</li>
<li>如果 repl 是函数，这个方法应当只接受一个参数（Match 对象），并返回一个字符串用于替换（返回的字符串中不能再引用分组）。</li>
<li>count 用于指定最多替换次数，不指定时全部替换。</li>
</ul>
</li>
<li><p>看看例子：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">p = re.compile(<span class="string">r'(\w+) (\w+)'</span>) <span class="comment"># \w = [A-Za-z0-9]</span></span><br><span class="line">s = <span class="string">'hello 123, hello 456'</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> p.sub(<span class="string">r'hello world'</span>, s)  <span class="comment"># 使用 'hello world' 替换 'hello 123' 和 'hello 456'</span></span><br><span class="line"><span class="keyword">print</span> p.sub(<span class="string">r'\2 \1'</span>, s)        <span class="comment"># 引用分组</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">func</span><span class="params">(m)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="string">'hi'</span> + <span class="string">' '</span> + m.group(<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> p.sub(func, s)</span><br><span class="line"><span class="keyword">print</span> p.sub(func, s, <span class="number">1</span>)         <span class="comment"># 最多替换一次</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>执行结果：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">hello world, hello world</span><br><span class="line"><span class="number">123</span> hello, <span class="number">456</span> hello</span><br><span class="line">hi <span class="number">123</span>, hi <span class="number">456</span></span><br><span class="line">hi <span class="number">123</span>, hello <span class="number">456</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="匹配中文"><a href="#匹配中文" class="headerlink" title="匹配中文"></a>匹配中文</h4><ul>
<li><p>在某些情况下，我们想匹配文本中的汉字，有一点需要注意的是，中文的 unicode 编码范围 主要在 [u4e00-u9fa5]，这里说主要是因为这个范围并不完整，比如没有包括全角（中文）标点，不过，在大部分情况下，应该是够用的。</p>
</li>
<li><p>假设现在想把字符串 title = u’你好，hello，世界’ 中的中文提取出来，可以这么做</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line">title = <span class="string">u'你好，hello，世界'</span></span><br><span class="line">pattern = re.compile(<span class="string">ur'[\u4e00-\u9fa5]+'</span>)</span><br><span class="line">result = pattern.findall(title)</span><br><span class="line"></span><br><span class="line"><span class="keyword">print</span> result</span><br></pre></td></tr></table></figure>
</li>
<li><p>注意到，我们在正则表达式前面加上了两个前缀 ur，其中 r 表示使用原始字符串，u 表示是 unicode 字符串。</p>
</li>
<li><p>执行结果:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[u&apos;\u4f60\u597d&apos;, u&apos;\u4e16\u754c&apos;]</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="注意：贪婪模式与非贪婪模式"><a href="#注意：贪婪模式与非贪婪模式" class="headerlink" title="注意：贪婪模式与非贪婪模式"></a>注意：贪婪模式与非贪婪模式</h4><ul>
<li><p>贪婪模式：在整个表达式匹配成功的前提下，尽可能多的匹配 ( * )；</p>
</li>
<li><p>非贪婪模式：在整个表达式匹配成功的前提下，尽可能少的匹配 ( ? )；</p>
</li>
<li><p><strong>Python里数量词默认是贪婪的</strong></p>
</li>
<li><p>示例一 ： 源字符串：abbbc</p>
<ul>
<li><p>使用贪婪的数量词的正则表达式 ab* ，匹配结果： abbb。</p>
<p>决定了尽可能多匹配 b，所以a后面所有的 b 都出现了。</p>
</li>
<li><p>使用非贪婪的数量词的正则表达式ab*?，匹配结果： a。</p>
<p>即使前面有 *，但是 ? 决定了尽可能少匹配 b，所以没有 b。</p>
</li>
</ul>
</li>
<li><p>示例二 ： 源字符串：<code>aa&lt;div&gt;test1&lt;/div&gt;bb&lt;div&gt;test2&lt;/div&gt;cc</code></p>
<ul>
<li>使用贪婪的数量词的正则表达式：<code>&lt;div&gt;.*&lt;/div&gt;</code><ul>
<li>匹配结果：<code>&lt;div&gt;test1&lt;/div&gt;bb&lt;div&gt;test2&lt;/div&gt;</code></li>
<li>这里采用的是贪婪模式。在匹配到第一个“<code>&lt;/div&gt;</code>”时已经可以使整个表达式匹配成功，但是由于采用的是贪婪模式，所以仍然要向右尝试匹配，查看是否还有更长的可以成功匹配的子串。匹配到第二个“<code>&lt;/div&gt;</code>”后，向右再没有可以成功匹配的子串，匹配结束，匹配结果为“<code>&lt;div&gt;test1&lt;/div&gt;bb&lt;div&gt;test2&lt;/div&gt;</code>”</li>
</ul>
</li>
<li>使用非贪婪的数量词的正则表达式：<code>&lt;div&gt;.*?&lt;/div&gt;</code><ul>
<li>匹配结果：<code>&lt;div&gt;test1&lt;/div&gt;</code></li>
<li>正则表达式二采用的是非贪婪模式，在匹配到第一个“<code>&lt;/div&gt;</code>”时使整个表达式匹配成功，由于采用的是非贪婪模式，所以结束匹配，不再向右尝试，匹配结果为“<code>&lt;div&gt;test1&lt;/div&gt;</code>”。</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="02-案例：使用正则的爬虫"><a href="#02-案例：使用正则的爬虫" class="headerlink" title="02-案例：使用正则的爬虫"></a>02-案例：使用正则的爬虫</h2><ul>
<li>现在拥有了正则表达式这把神兵利器，我们就可以进行对爬取到的全部网页源代码进行筛选了。</li>
<li>下面我们一起尝试一下爬取内涵段子网站： <a href="http://www.neihan8.com/article/list_5_1.html" target="_blank" rel="noopener">http://www.neihan8.com/article/list_5_1.html</a></li>
<li>打开之后，不难看到里面一个一个灰常有内涵的段子，当你进行翻页的时候，注意url地址的变化：<ul>
<li>第一页url: http: //<a href="http://www.neihan8.com/article/list_5_1" target="_blank" rel="noopener">www.neihan8.com/article/list_5_1</a> .html</li>
<li>第二页url: http: //<a href="http://www.neihan8.com/article/list_5_2" target="_blank" rel="noopener">www.neihan8.com/article/list_5_2</a> .html</li>
<li>第三页url: http: //<a href="http://www.neihan8.com/article/list_5_3" target="_blank" rel="noopener">www.neihan8.com/article/list_5_3</a> .html</li>
<li>第四页url: http: //<a href="http://www.neihan8.com/article/list_5_4" target="_blank" rel="noopener">www.neihan8.com/article/list_5_4</a> .html</li>
</ul>
</li>
<li>这样我们的url规律找到了，要想爬取所有的段子，只需要修改一个参数即可。 下面我们就开始一步一步将所有的段子爬取下来吧。</li>
</ul>
<h3 id="2-1-第一步：获取数据"><a href="#2-1-第一步：获取数据" class="headerlink" title="2.1-第一步：获取数据"></a>2.1-第一步：获取数据</h3><ul>
<li><p>按照我们之前的用法，我们需要写一个加载页面的方法</p>
<ul>
<li><p>这里我们统一定义一个类，将url请求作为一个成员方法处理</p>
</li>
<li><p>我们创建一个文件，叫duanzi_spider.py</p>
</li>
<li><p>然后定义一个Spider类，并且添加一个加载页面的成员方法</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> urllib2</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Spider</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">        内涵段子爬虫类</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">loadPage</span><span class="params">(self, page)</span>:</span></span><br><span class="line">        <span class="string">"""</span></span><br><span class="line"><span class="string">            @brief 定义一个url请求网页的方法</span></span><br><span class="line"><span class="string">            @param page 需要请求的第几页</span></span><br><span class="line"><span class="string">            @returns 返回的页面html</span></span><br><span class="line"><span class="string">        """</span></span><br><span class="line"></span><br><span class="line">    url = <span class="string">"http://www.neihan8.com/article/list_5_"</span> + str(page)</span><br><span class="line">+ <span class="string">".html"</span></span><br><span class="line">    <span class="comment">#User-Agent头</span></span><br><span class="line">    user_agent = <span class="string">'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT</span></span><br><span class="line"><span class="string">6.1; Trident/5.0'</span></span><br><span class="line"></span><br><span class="line">    headers = &#123;<span class="string">'User-Agent'</span>: user_agent&#125;</span><br><span class="line">    req = urllib2.Request(url, headers = headers)</span><br><span class="line">    response = urllib2.urlopen(req)</span><br><span class="line">    html = response.read()</span><br><span class="line">    <span class="keyword">print</span> html</span><br><span class="line"></span><br><span class="line">    <span class="comment">#return html</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>以上的loadPage的实现体想必大家应该很熟悉了，需要注意定义python类的成员方法需要额外添加一个参数self.</p>
<ul>
<li>那么loadPage(self, page) 中的page是我们指定去请求第几页。</li>
<li>最后通过 print html打印到屏幕上。</li>
<li>然后我们写一个main函数见到测试一个loadPage方法</li>
</ul>
</li>
</ul>
</li>
<li><p>写main函数测试一个loadPage方法</p>
<ul>
<li><p>code</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">        ======================</span></span><br><span class="line"><span class="string">            内涵段子小爬虫</span></span><br><span class="line"><span class="string">        ======================</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">'请按下回车开始'</span></span><br><span class="line">    raw_input()</span><br><span class="line"></span><br><span class="line">    <span class="comment">#定义一个Spider对象</span></span><br><span class="line">    mySpider = Spider()</span><br><span class="line">    mySpider.loadpage(<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
</li>
<li><p>程序正常执行的话，我们会在屏幕上打印了内涵段子第一页的全部html代码。 但是我们发现，html中的中文部分显示的可能是乱码 。</p>
<p><img src="http://ot12pfxkm.bkt.clouddn.com/18-1-4/95218382.jpg" alt></p>
</li>
</ul>
</li>
<li><p>我们需要简单的将得到的网页源代码处理一下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadPage</span><span class="params">(self, page)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">        @brief 定义一个url请求网页的方法</span></span><br><span class="line"><span class="string">        @param page 需要请求的第几页</span></span><br><span class="line"><span class="string">        @returns 返回的页面html</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    url = <span class="string">"http://www.neihan8.com/article/list_5_"</span> + str(page)</span><br><span class="line">+ <span class="string">".html"</span></span><br><span class="line">    <span class="comment">#User-Agent头</span></span><br><span class="line">    user_agent = <span class="string">'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT</span></span><br><span class="line"><span class="string">6.1; Trident/5.0'</span></span><br><span class="line">    headers = &#123;<span class="string">'User-Agent'</span>: user_agent&#125;</span><br><span class="line">    req = urllib2.Request(url, headers = headers)</span><br><span class="line">    response = urllib2.urlopen(req)</span><br><span class="line">    html = response.read()</span><br><span class="line">    gbk_html = html.decode(<span class="string">'gbk'</span>).encode(<span class="string">'utf-8'</span>)</span><br><span class="line">    <span class="comment"># print gbk_html</span></span><br><span class="line">    <span class="keyword">return</span> gbk_html</span><br></pre></td></tr></table></figure>
<ul>
<li><p>注意 ：对于每个网站对中文的编码各自不同，所以html.decode(‘gbk’)的写法并不是通用写法，根据网站的编码而异</p>
</li>
<li><p>这样我们再次执行以下duanzi_spider.py ，会发现之前的中文乱码可以正常显示了。</p>
<p><img src="http://ot12pfxkm.bkt.clouddn.com/18-1-4/63978114.jpg" alt></p>
</li>
</ul>
</li>
</ul>
<h3 id="2-2-第二步：筛选数据"><a href="#2-2-第二步：筛选数据" class="headerlink" title="2.2-第二步：筛选数据"></a>2.2-第二步：筛选数据</h3><ul>
<li><p>接下来我们已经得到了整个页面的数据。 但是，很多内容我们并不关心，所以下一步我们需要进行筛选。 如何筛选，就用到了上一节讲述的正则表达式。</p>
<ul>
<li>首先，<code>import re</code></li>
<li>然后, 在我们得到的<code>gbk_html</code>中进行筛选匹配。</li>
</ul>
</li>
<li><p>需要一个匹配规则:</p>
<ul>
<li><p>我们可以打开内涵段子的网页，鼠标点击右键 “ 查看源代码 ” 你会惊奇的发现，我们需要的每个段子的内容都是在一个 <code>&lt;div&gt;</code>标签中，而且每个<code>div</code>都有一个属性<code>class = &quot;f18 mb20&quot;</code></p>
<p><img src="http://ot12pfxkm.bkt.clouddn.com/18-1-4/92466482.jpg" alt></p>
<ul>
<li>所以，我们只需要匹配到网页中所有<code>&lt;div class=&quot;f18 mb20&quot;&gt;</code> 到 <code>&lt;/div&gt;</code> 的数据就可以了。</li>
</ul>
</li>
</ul>
</li>
<li><p>根据正则表达式，我们可以推算出一个公式是</p>
<ul>
<li><p><code>&lt;div.*?class=&quot;f18 mb20&quot;&gt;(.*?)&lt;/div&gt;</code></p>
</li>
<li><p>这个表达式实际上就是匹配到所有<code>div</code>中<code>class=&quot;f18 mb20</code> 里面的内容(具体可以看前面正则介绍)</p>
</li>
<li><p>然后将这个正则应用到代码中，我们会得到以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadPage</span><span class="params">(self, page)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">        @brief 定义一个url请求网页的方法</span></span><br><span class="line"><span class="string">        @param page 需要请求的第几页</span></span><br><span class="line"><span class="string">        @returns 返回的页面html</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line"></span><br><span class="line">    url = <span class="string">"http://www.neihan8.com/article/list_5_"</span> + str(page)</span><br><span class="line">+ <span class="string">".html"</span></span><br><span class="line">    <span class="comment">#User-Agent头</span></span><br><span class="line">    user_agent = <span class="string">'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT</span></span><br><span class="line"><span class="string">6.1; Trident/5.0'</span></span><br><span class="line">    headers = &#123;<span class="string">'User-Agent'</span>: user_agent&#125;</span><br><span class="line">    req = urllib2.Request(url, headers = headers)</span><br><span class="line">    response = urllib2.urlopen(req)</span><br><span class="line">    html = response.read()</span><br><span class="line">    gbk_html = html.decode(<span class="string">'gbk'</span>).encode(<span class="string">'utf-8'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#找到所有的段子内容&lt;div class = "f18 mb20"&gt;&lt;/div&gt;</span></span><br><span class="line">    <span class="comment">#re.S 如果没有re.S 则是只匹配一行有没有符合规则的字符串，如果没有则下一行重新匹配</span></span><br><span class="line">    <span class="comment"># 如果加上re.S 则是将所有的字符串将一个整体进行匹配</span></span><br><span class="line">    pattern = re.compile(<span class="string">r'&lt;div.*?class="f18 mb20"&gt;(.*?)&lt;/di</span></span><br><span class="line"><span class="string">v&gt;'</span>, re.S)</span><br><span class="line">    item_list = pattern.findall(gbk_html)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> item_list</span><br></pre></td></tr></table></figure>
<p>def printOnePage(self, item_list, page):</p>
<pre><code>&quot;&quot;&quot;
    @brief 处理得到的段子列表
    @param item_list 得到的段子列表
    @param page 处理第几页
&quot;&quot;&quot;

print &quot;******* 第 %d 页 爬取完毕...*******&quot; %page
for item in item_list:
    print &quot;================&quot;
    print ite
</code></pre><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">  - 这里需要注意一个是`re.S`是正则表达式中匹配的一个参数。</span><br><span class="line"></span><br><span class="line">  - 如果 没有re.S 则是 只匹配一行 有没有符合规则的字符串，如果没有则下一行重新匹配。</span><br><span class="line"></span><br><span class="line">  - 如果 加上re.S 则是将 所有的字符串 将一个整体进行匹配，findall 将所有匹配到的结果封装到一个list中。</span><br><span class="line"></span><br><span class="line">  - 然后我们写了一个遍历`item_list`的一个方法 `printOnePage()` 。 ok程序写到这，我们再一次执行一下。</span><br><span class="line"></span><br><span class="line">    `Power@PowerMac ~$ python duanzi_spider.py`</span><br><span class="line"></span><br><span class="line">- 我们第一页的全部段子，不包含其他信息全部的打印了出来</span><br><span class="line"></span><br><span class="line">  - 你会发现段子中有很多 `&lt;p&gt;` , `&lt;/p&gt;` 很是不舒服，实际上这个是html的一种段落的标签。</span><br><span class="line"></span><br><span class="line">  - 在浏览器上看不出来，但是如果按照文本打印会有`&lt;p&gt;`出现，那么我们只需要把我们不希望的内容去掉即可了。</span><br><span class="line"></span><br><span class="line">  - 我们可以如下简单修改一下 printOnePage().</span><br><span class="line"></span><br><span class="line">    ```python</span><br><span class="line">    def printOnePage(self, item_list, page):</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">            @brief 处理得到的段子列表</span><br><span class="line">            @param item_list 得到的段子列表</span><br><span class="line">            @param page 处理第几页</span><br><span class="line">        &quot;&quot;&quot;</span><br><span class="line">    </span><br><span class="line">        print &quot;******* 第 %d 页 爬取完毕...*******&quot; %page</span><br><span class="line">        for item in item_list:</span><br><span class="line">            print &quot;================&quot;</span><br><span class="line">            item = item.replace(&quot;&lt;p&gt;&quot;, &quot;&quot;).replace(&quot;&lt;/p&gt;&quot;, &quot;&quot;).repl</span><br><span class="line">    ace(&quot;&lt;br /&gt;&quot;, &quot;&quot;)</span><br><span class="line">            print item</span><br></pre></td></tr></table></figure>
</li>
</ul>
</li>
</ul>
<h3 id="2-3-第三步：保存数据"><a href="#2-3-第三步：保存数据" class="headerlink" title="2.3-第三步：保存数据"></a>2.3-第三步：保存数据</h3><ul>
<li><p>我们可以将所有的段子存放在文件中。比如，我们可以将得到的每个item不是打印出来，而是存放在一个叫 duanzi.txt 的文件中也可以。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">writeToFile</span><span class="params">(self, text)</span>:</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">    @brief 将数据追加写进文件中</span></span><br><span class="line"><span class="string">    @param text 文件内容</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">    myFile = open(<span class="string">"./duanzi.txt"</span>, <span class="string">'a'</span>) <span class="comment">#追加形式打开文件</span></span><br><span class="line">    myFile.write(text)</span><br><span class="line">    myFile.write(<span class="string">"---------------------------------------------</span></span><br><span class="line"><span class="string">--------"</span>)</span><br><span class="line">    myFile.close()</span><br></pre></td></tr></table></figure>
</li>
<li><p>然后我们将print的语句 改成<code>writeToFile()</code> ，当前页面的所有段子就存在了本地的MyStory.txt文件中。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">printOnePage</span><span class="params">(self, item_list, page)</span>:</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">    @brief 处理得到的段子列表</span></span><br><span class="line"><span class="string">    @param item_list 得到的段子列表</span></span><br><span class="line"><span class="string">    @param page 处理第几页</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">    <span class="keyword">print</span> <span class="string">"******* 第 %d 页 爬取完毕...*******"</span> %page</span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> item_list:</span><br><span class="line">        <span class="comment"># print "================"</span></span><br><span class="line">        item = item.replace(<span class="string">"&lt;p&gt;"</span>, <span class="string">""</span>).replace(<span class="string">"&lt;/p&gt;"</span>, <span class="string">""</span>).repl</span><br><span class="line">ace(<span class="string">"&lt;br /&gt;"</span>, <span class="string">""</span>)</span><br><span class="line">        <span class="comment"># print item</span></span><br><span class="line">        self.writeToFile(item)</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="2-4-第四步：显示数据"><a href="#2-4-第四步：显示数据" class="headerlink" title="2.4-第四步：显示数据"></a>2.4-第四步：显示数据</h3><ul>
<li><p>接下来我们就通过参数的传递对page进行叠加来遍历 内涵段子吧的全部段子内容</p>
</li>
<li><p>只需要在外层加一些逻辑处理即可。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">doWork</span><span class="params">(self)</span>:</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line"><span class="string">    让爬虫开始工作</span></span><br><span class="line"><span class="string">'''</span></span><br><span class="line">    <span class="keyword">while</span> self.enable:</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            item_list = self.loadPage(self.page)</span><br><span class="line">        <span class="keyword">except</span> urllib2.URLError, e:</span><br><span class="line">            <span class="keyword">print</span> e.reason</span><br><span class="line">            <span class="keyword">continue</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">#对得到的段子item_list处理</span></span><br><span class="line">        self.printOnePage(item_list, self.page)</span><br><span class="line">        self.page += <span class="number">1</span> <span class="comment">#此页处理完毕，处理下一页</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">"按回车继续..."</span></span><br><span class="line">        <span class="keyword">print</span> <span class="string">"输入 quit 退出"</span></span><br><span class="line">        command = raw_input()</span><br><span class="line">        <span class="keyword">if</span> (command == <span class="string">"quit"</span>):</span><br><span class="line">            self.enable = <span class="keyword">False</span></span><br><span class="line">            <span class="keyword">break</span></span><br></pre></td></tr></table></figure>
<ul>
<li>最后，我们执行我们的代码，完成后查看当前路径下的duanzi.txt文件，里面已经有了我们要的内涵段子。</li>
</ul>
</li>
<li><p>以上便是一个非常精简使用的小爬虫程序，使用起来很是方便，如果想要爬取其他网站的信息，只需要修改其中某些参数和一些细节就行了</p>
</li>
</ul>
<p>## </p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/python/" rel="tag"># python</a>
          
            <a href="/tags/爬虫/" rel="tag"># 爬虫</a>
          
            <a href="/tags/数据提取/" rel="tag"># 数据提取</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/01/04/非结构化数据-结构化数据提取-4/" rel="next" title="非结构化数据&结构化数据提取-4">
                <i class="fa fa-chevron-left"></i> 非结构化数据&结构化数据提取-4
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/01/04/爬虫原理-数据抓取-1/" rel="prev" title="爬虫原理&数据抓取-1">
                爬虫原理&数据抓取-1 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="Ry1ynn">
            
              <p class="site-author-name" itemprop="name">Ry1ynn</p>
              <p class="site-description motion-element" itemprop="description">我们的征途是星辰大海</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">118</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">15</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">53</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/Ry1ynn" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:ry1ynn_pri@163.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="https://weibo.com/u/5794121667" target="_blank" title="Weibo">
                      
                        <i class="fa fa-fw fa-weibo"></i>Weibo</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="/images/weixin.JPG" target="_blank" title="Wechat">
                      
                        <i class="fa fa-fw fa-weixin"></i>Wechat</a>
                  </span>
                
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.t00ls.net/" title="T00ls" target="_blank">T00ls</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.freebuf.com/" title="FreeBuf" target="_blank">FreeBuf</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.sec-wiki.com/" title="SecWiki" target="_blank">SecWiki</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.seebug.org/" title="Seebug" target="_blank">Seebug</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="http://www.91ri.org/" title="91Ri" target="_blank">91Ri</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.pediy.com/" title="看雪" target="_blank">看雪</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.52pojie.cn/" title="吾爱破解" target="_blank">吾爱破解</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.anquanke.com/" title="安全客" target="_blank">安全客</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.ichunqiu.com/" title="i春秋" target="_blank">i春秋</a>
                  </li>
                
              </ul>
            </div>
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#非结构化数据-amp-结构化数据提取"><span class="nav-text">非结构化数据&amp;结构化数据提取</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#00-简介"><span class="nav-text">00-简介</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#01-正则表达式re模块"><span class="nav-text">01-正则表达式re模块</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#1-1-为何学正则表达式"><span class="nav-text">1.1-为何学正则表达式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-2-何为正则表达式"><span class="nav-text">1.2-何为正则表达式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-3-正则表达式匹配规则"><span class="nav-text">1.3-正则表达式匹配规则</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#1-4-python中的re模块"><span class="nav-text">1.4-python中的re模块</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#compile函数"><span class="nav-text">compile函数</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#match-方法"><span class="nav-text">match 方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#search方法"><span class="nav-text">search方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#findall方法"><span class="nav-text">findall方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#finditer-方法"><span class="nav-text">finditer 方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#split方法"><span class="nav-text">split方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#sub方法"><span class="nav-text">sub方法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#匹配中文"><span class="nav-text">匹配中文</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#注意：贪婪模式与非贪婪模式"><span class="nav-text">注意：贪婪模式与非贪婪模式</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#02-案例：使用正则的爬虫"><span class="nav-text">02-案例：使用正则的爬虫</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-第一步：获取数据"><span class="nav-text">2.1-第一步：获取数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-第二步：筛选数据"><span class="nav-text">2.2-第二步：筛选数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-第三步：保存数据"><span class="nav-text">2.3-第三步：保存数据</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-第四步：显示数据"><span class="nav-text">2.4-第四步：显示数据</span></a></li></ol></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2016 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ry1ynn</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  










  



  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script id="ribbon" type="text/javascript" size="300" alpha="0.5" zindex="0" src="/lib/canvas-ribbon/canvas-ribbon.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
